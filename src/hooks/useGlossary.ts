
// hooks/useGlossary.ts
// ìš©ì–´ì§‘ ê¸°ëŠ¥ì„ ìœ„í•œ ì»¤ìŠ¤í…€ í›…

import { useCallback, useRef, useEffect } from 'react';
import { useGlossaryStore } from '../stores/glossaryStore';
import { useSettingsStore } from '../stores/settingsStore';
import { useTranslationStore } from '../stores/translationStore';
import { GlossaryService } from '../services/GlossaryService';
import { ChunkService } from '../services/ChunkService'; // [ì¶”ê°€] ChunkService ì„í¬íŠ¸
import type { GlossaryExtractionProgress, GlossaryEntry } from '../types/dtos';

/**
 * ìš©ì–´ì§‘ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ì»¤ìŠ¤í…€ í›…
 * GlossaryServiceì™€ ìŠ¤í† ì–´ë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.
 */
export function useGlossary() {
  // ìŠ¤í† ì–´ ìƒíƒœ
  const { config } = useSettingsStore();
  const { inputFiles } = useTranslationStore();
  const {
    entries,
    isExtracting,
    extractionProgress,
    startExtraction,
    stopExtraction,
    updateExtractionProgress,
    mergeEntries,
    setEntries,
    clearEntries,
    exportToJson,
    importFromJson,
    // [ì¶”ê°€] í ê´€ë ¨ ìƒíƒœ ë° ì•¡ì…˜
    extractionQueue,
    initialTotalSegments,
    setExtractionQueue,
    clearExtractionQueue
  } = useGlossaryStore();

  // ë¡œê·¸ ì¶”ê°€ í•¨ìˆ˜
  const { addLog } = useTranslationStore();

  // ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ì°¸ì¡°
  const serviceRef = useRef<GlossaryService | null>(null);
  const isExtractingRef = useRef(false);

  // ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ë˜ëŠ” ì—…ë°ì´íŠ¸
  const getOrCreateService = useCallback((): GlossaryService => {
    if (!serviceRef.current) {
      serviceRef.current = new GlossaryService(config);
      
      // ë¡œê·¸ ì½œë°± ì„¤ì •
      serviceRef.current.setLogCallback((entry) => {
        addLog(entry.level, entry.message);
      });
    } else {
      // ì„¤ì • ì—…ë°ì´íŠ¸
      serviceRef.current.updateConfig(config);
    }

    return serviceRef.current;
  }, [config, addLog]);

  // ìš©ì–´ì§‘ ì¶”ì¶œ ì‹œì‘ (resume íŒŒë¼ë¯¸í„° ì¶”ê°€)
  const executeExtraction = useCallback(async (sourceText?: string, resume: boolean = false) => {
    if (isExtractingRef.current) {
      addLog('warning', 'ì´ë¯¸ ìš©ì–´ì§‘ ì¶”ì¶œì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.');
      return;
    }

    // ì‚¬ìš©í•  ì„¸ê·¸ë¨¼íŠ¸ í ì¤€ë¹„
    let segmentsToProcess: string[] = [];
    let totalSegmentsForProgress = 0;

    // 1. ì´ì–´í•˜ê¸° ëª¨ë“œ
    if (resume && extractionQueue.length > 0) {
      segmentsToProcess = extractionQueue;
      totalSegmentsForProgress = initialTotalSegments > 0 ? initialTotalSegments : extractionQueue.length;
      addLog('info', `ğŸ”„ ì´ì „ì— ì¤‘ë‹¨ëœ ì‘ì—… ${segmentsToProcess.length}ê°œ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì´ì–´í•©ë‹ˆë‹¤.`);
    } 
    // 2. ìƒˆë¡œ ì‹œì‘ ëª¨ë“œ
    else {
      // ì†ŒìŠ¤ í…ìŠ¤íŠ¸ ê²°ì •
      let textToAnalyze = sourceText;
      
      if (!textToAnalyze) {
        if (inputFiles.length === 0) {
          addLog('warning', 'ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.');
          return;
        }

        const extractedTexts = inputFiles.map(f => {
          if (f.isEpub && f.epubChapters && f.epubChapters.length > 0) {
            return f.epubChapters
              .flatMap((ch: any) => ch.nodes)
              .filter((n: any) => n.type === 'text' && n.content)
              .map((n: any) => n.content)
              .join('\n');
          }
          return f.content;
        });

        textToAnalyze = extractedTexts.join('\n\n');

        if (!textToAnalyze.trim()) {
          addLog('warning', 'ë¶„ì„í•  í…ìŠ¤íŠ¸ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤ (EPUB íŒŒì¼ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ê°€ ì—†ìŒ).');
          return;
        }
      }

      // ìƒˆ ì‘ì—…ì´ë¯€ë¡œ í…ìŠ¤íŠ¸ ë¶„í•  ë° ìƒ˜í”Œë§ ìˆ˜í–‰
      // [ìˆ˜ì •] GlossaryService ë‚´ë¶€ private ë©”ì†Œë“œì¸ selectSampleSegmentsë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ,
      // ì—¬ê¸°ì„œ ì§ì ‘ ChunkServiceë¥¼ ì´ìš©í•´ ë¶„í• í•˜ê³  ìƒ˜í”Œë§ ë¡œì§ì„ êµ¬í˜„í•˜ê±°ë‚˜, 
      // ì„œë¹„ìŠ¤ë¥¼ í†µí•´ ìƒ˜í”Œë§ëœ ëª©ë¡ì„ ë°›ì•„ì™€ì•¼ í•¨.
      // í•˜ì§€ë§Œ ê°€ì¥ ê¹”ë”í•œ ë°©ë²•ì€: 
      // 1. Chunking 2. Samplingì„ ì—¬ê¸°ì„œ ìˆ˜í–‰í•˜ê³  3. Queueì— ì €ì¥í•˜ëŠ” ê²ƒ.
      
      const chunkService = new ChunkService(config.glossaryChunkSize || config.chunkSize || 8000);
      const allSegments = chunkService.createChunksFromFileContent(textToAnalyze, config.glossaryChunkSize);
      
      // ìƒ˜í”Œë§ ë¡œì§ (Fisher-Yates)
      const samplingRatio = (config.glossarySamplingRatio || 10) / 100;
      const sampleSize = Math.max(1, Math.floor(allSegments.length * samplingRatio));
      
      const indices = Array.from({ length: allSegments.length }, (_, i) => i);
      for (let i = allSegments.length - 1; i > 0; i--) {
        const j = Math.floor(Math.random() * (i + 1));
        [indices[i], indices[j]] = [indices[j], indices[i]];
      }
      const selectedIndices = indices.slice(0, sampleSize).sort((a, b) => a - b);
      segmentsToProcess = selectedIndices.map(i => allSegments[i]);
      
      totalSegmentsForProgress = segmentsToProcess.length;
      
      // [ì¤‘ìš”] í ì´ˆê¸°í™” ë° ì €ì¥
      setExtractionQueue(segmentsToProcess, totalSegmentsForProgress);
      
      addLog('info', `ìš©ì–´ì§‘ ì¶”ì¶œ ì‹œì‘ (ëª¨ë¸: ${config.modelName})`);
      addLog('info', `ë¶„ì„í•  í…ìŠ¤íŠ¸: ${textToAnalyze.length.toLocaleString()}ì, í‘œë³¸ ì„¸ê·¸ë¨¼íŠ¸: ${segmentsToProcess.length}ê°œ`);
    }

    isExtractingRef.current = true;
    startExtraction();

    // ì²˜ë¦¬ëœ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜ë¥¼ ì¶”ì í•˜ê¸° ìœ„í•œ ë³€ìˆ˜
    let processedCountInThisRun = 0;

    try {
      const service = getOrCreateService();

      // ì§„í–‰ë¥  ì½œë°± (Global Progress ê³„ì‚°)
      const onProgress = (progress: GlossaryExtractionProgress) => {
        processedCountInThisRun = progress.processedSegments;
        
        // ì „ì²´ ì§„í–‰ë¥  = (ì „ì²´ - í˜„ì¬íê¸¸ì´) + ì´ë²ˆì‹¤í–‰ì²˜ë¦¬ìˆ˜
        const globalProcessed = (totalSegmentsForProgress - segmentsToProcess.length) + processedCountInThisRun;
        
        updateExtractionProgress({
          ...progress,
          totalSegments: totalSegmentsForProgress, // ì „ì²´ ê¸°ì¤€
          processedSegments: Math.min(globalProcessed, totalSegmentsForProgress)
        });
      };

      const stopCheck = () => !isExtractingRef.current;
      const seedEntries = entries.length > 0 ? entries : undefined;

      // ìš©ì–´ì§‘ ì¶”ì¶œ ì‹¤í–‰ (preSelectedSegments ì „ë‹¬)
      const extractedEntries = await service.extractGlossary(
        "", // í…ìŠ¤íŠ¸ëŠ” íê°€ ìˆìœ¼ë©´ ë¬´ì‹œë¨
        onProgress,
        seedEntries,
        config.glossaryExtractionPrompt,
        stopCheck,
        segmentsToProcess // í ì „ë‹¬
      );

      if (extractedEntries.length > 0) {
        mergeEntries(extractedEntries);
        addLog('info', `ìš©ì–´ì§‘ ì¶”ì¶œ ì™„ë£Œ: ${extractedEntries.length}ê°œ í•­ëª©`);
      } else {
        addLog('warning', 'ì¶”ì¶œëœ ìš©ì–´ì§‘ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.');
      }

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      addLog('error', `ìš©ì–´ì§‘ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: ${errorMessage}`);
      
      updateExtractionProgress({
        totalSegments: 0,
        processedSegments: 0,
        currentStatusMessage: `ì˜¤ë¥˜: ${errorMessage}`,
        extractedEntriesCount: entries.length,
      });
    } finally {
      // [ì¤‘ìš”] ì¤‘ë‹¨ ì‹œì  ì €ì¥ (Queue ì—…ë°ì´íŠ¸)
      // processedCountInThisRun ë§Œí¼ í ì•ì—ì„œ ì œê±°
      const remainingSegments = segmentsToProcess.slice(processedCountInThisRun);
      
      if (remainingSegments.length > 0) {
        setExtractionQueue(remainingSegments, totalSegmentsForProgress);
        addLog('info', `ì‘ì—…ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ë‚¨ì€ ${remainingSegments.length}ê°œ ì„¸ê·¸ë¨¼íŠ¸ëŠ” ëŒ€ê¸°ì—´ì— ë³´ì¡´ë©ë‹ˆë‹¤.`);
      } else {
        clearExtractionQueue(); // ì™„ë£Œë˜ë©´ í ë¹„ì›€
      }

      isExtractingRef.current = false;
      stopExtraction();
    }
  }, [
    inputFiles,
    config,
    entries,
    extractionQueue,
    initialTotalSegments,
    getOrCreateService,
    startExtraction,
    stopExtraction,
    updateExtractionProgress,
    mergeEntries,
    setExtractionQueue,
    clearExtractionQueue,
    addLog,
  ]);

  // ìš©ì–´ì§‘ ì¶”ì¶œ ì¤‘ì§€
  const cancelExtraction = useCallback(() => {
    if (serviceRef.current) {
      serviceRef.current.requestStop();
    }
    // isExtractingRef.current = false; // ì„œë¹„ìŠ¤ê°€ ë©ˆì¶”ê³  finally ë¸”ë¡ì—ì„œ ì²˜ë¦¬ë˜ë„ë¡ ìœ ë„
    addLog('warning', 'ìš©ì–´ì§‘ ì¶”ì¶œì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë©ˆì¶¥ë‹ˆë‹¤...');
  }, [addLog]);

  // ìš©ì–´ì§‘ JSON ë‹¤ìš´ë¡œë“œ
  const downloadGlossary = useCallback((filename?: string) => {
    if (entries.length === 0) {
      addLog('warning', 'ë‹¤ìš´ë¡œë“œí•  ìš©ì–´ì§‘ì´ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }

    const json = exportToJson();
    const blob = new Blob([json], { type: 'application/json;charset=utf-8' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = filename || `glossary_${new Date().toISOString().slice(0, 10)}.json`;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    URL.revokeObjectURL(url);

    addLog('info', `ìš©ì–´ì§‘ì´ ë‹¤ìš´ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤: ${a.download}`);
  }, [entries, exportToJson, addLog]);

  // ìš©ì–´ì§‘ CSV ë‹¤ìš´ë¡œë“œ
  const downloadGlossaryCsv = useCallback((filename?: string) => {
    if (entries.length === 0) {
      addLog('warning', 'ë‹¤ìš´ë¡œë“œí•  ìš©ì–´ì§‘ì´ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }

    const sortedEntries = [...entries].sort((a, b) => {
      if (b.occurrenceCount !== a.occurrenceCount) {
        return b.occurrenceCount - a.occurrenceCount;
      }
      return a.keyword.localeCompare(b.keyword);
    });

    const headers = ['keyword', 'translatedKeyword', 'targetLanguage', 'occurrenceCount'];
    const csvRows = [headers.join(',')];
    
    for (const entry of sortedEntries) {
      const row = [
        `"${entry.keyword.replace(/"/g, '""')}"`,
        `"${entry.translatedKeyword.replace(/"/g, '""')}"`,
        entry.targetLanguage,
        entry.occurrenceCount.toString(),
      ];
      csvRows.push(row.join(','));
    }

    const csv = csvRows.join('\n');
    const blob = new Blob(['\uFEFF' + csv], { type: 'text/csv;charset=utf-8' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = filename || `glossary_${new Date().toISOString().slice(0, 10)}.csv`;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    URL.revokeObjectURL(url);

    addLog('info', `ìš©ì–´ì§‘ CSVê°€ ë‹¤ìš´ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤: ${a.download}`);
  }, [entries, addLog]);

  // ìš©ì–´ì§‘ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
  const importGlossaryFile = useCallback(async () => {
    try {
      const input = document.createElement('input');
      input.type = 'file';
      input.accept = '.json,.csv';
      
      return new Promise<boolean>((resolve) => {
        input.onchange = async (e) => {
          const file = (e.target as HTMLInputElement).files?.[0];
          if (!file) {
            resolve(false);
            return;
          }

          try {
            const content = await file.text();
            
            if (file.name.endsWith('.json')) {
              const success = importFromJson(content);
              if (success) {
                addLog('info', `ìš©ì–´ì§‘ JSON íŒŒì¼ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤: ${file.name}`);
              } else {
                addLog('error', 'ìš©ì–´ì§‘ JSON íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨');
              }
              resolve(success);
            } else if (file.name.endsWith('.csv')) {
              const lines = content.split('\n');
              if (lines.length < 2) {
                addLog('error', 'CSV íŒŒì¼ì´ ë¹„ì–´ ìˆê±°ë‚˜ í—¤ë”ë§Œ ìˆìŠµë‹ˆë‹¤.');
                resolve(false);
                return;
              }

              const newEntries: GlossaryEntry[] = [];
              for (let i = 1; i < lines.length; i++) {
                const line = lines[i].trim();
                if (!line) continue;

                const match = line.match(/^"([^"]*?)","([^"]*?)",([^,]+),(\d+)$/);
                if (match) {
                  newEntries.push({
                    keyword: match[1].replace(/""/g, '"'),
                    translatedKeyword: match[2].replace(/""/g, '"'),
                    targetLanguage: match[3],
                    occurrenceCount: parseInt(match[4]) || 0,
                  });
                }
              }

              if (newEntries.length > 0) {
                mergeEntries(newEntries);
                addLog('info', `CSVì—ì„œ ${newEntries.length}ê°œ í•­ëª©ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤: ${file.name}`);
                resolve(true);
              } else {
                addLog('error', 'CSV íŒŒì¼ì—ì„œ ìœ íš¨í•œ í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
                resolve(false);
              }
            } else {
              addLog('error', 'ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.');
              resolve(false);
            }
          } catch (error) {
            addLog('error', `íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: ${error}`);
            resolve(false);
          }
        };

        input.click();
      });
    } catch (error) {
      addLog('error', `íŒŒì¼ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: ${error}`);
      return false;
    }
  }, [importFromJson, mergeEntries, addLog]);

  // ìš©ì–´ì§‘ ì´ˆê¸°í™”
  const resetGlossary = useCallback(() => {
    clearEntries();
    clearExtractionQueue(); // [ì¶”ê°€] íë„ ì´ˆê¸°í™”
    addLog('info', 'ìš©ì–´ì§‘ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.');
  }, [clearEntries, clearExtractionQueue, addLog]);

  useEffect(() => {
    return () => {
      if (serviceRef.current) {
        serviceRef.current.requestStop();
      }
    };
  }, []);

  return {
    entries,
    isExtracting,
    extractionProgress,
    extractionQueue, // [ì¶”ê°€]
    executeExtraction,
    cancelExtraction,
    downloadGlossary,
    downloadGlossaryCsv,
    importGlossaryFile,
    resetGlossary,
    canExtract: inputFiles.length > 0 && !isExtracting,
    canStop: isExtracting,
    hasEntries: entries.length > 0,
    entryCount: entries.length,
  };
}
